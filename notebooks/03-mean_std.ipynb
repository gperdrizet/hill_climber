{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94faa477",
   "metadata": {},
   "source": [
    "# Example climb: Matching means and standard deviations with maximum structural diversity\n",
    "\n",
    "## 1. Notebook setup\n",
    "\n",
    "### 1.1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from hill_climber import HillClimber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520de678",
   "metadata": {},
   "source": [
    "### 1.2. Run hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input data points\n",
    "n = 5000\n",
    "\n",
    "# Run duration in minutes\n",
    "run_time = 60\n",
    "\n",
    "# Number of replicate climbs\n",
    "replicates = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e6602",
   "metadata": {},
   "source": [
    "### 1.3. Input distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288538ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input distributions (4 variables, all strictly positive)\n",
    "# Start with similar normal distributions that will be evolved into different structures\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'w': np.random.normal(loc=10.0, scale=2.0, size=n),\n",
    "    'x': np.random.normal(loc=10.0, scale=2.0, size=n),\n",
    "    'y': np.random.normal(loc=10.0, scale=2.0, size=n),\n",
    "    'z': np.random.normal(loc=10.0, scale=2.0, size=n)\n",
    "})\n",
    "\n",
    "# Ensure all values are strictly positive by clipping any negative values\n",
    "for col in data.columns:\n",
    "    data[col] = np.maximum(data[col], 0.1)  # Minimum value of 0.1\n",
    "\n",
    "print(\"Initial statistics:\")\n",
    "\n",
    "for col in data.columns:\n",
    "    print(f\"Mean {col}: {np.mean(data[col]):.4f}\")\n",
    "\n",
    "print(f\"\\nInitial pairwise KS statistics (similarity):\")\n",
    "\n",
    "for col1, col2 in combinations(data.columns, 2):\n",
    "    ks_stat, _ = stats.ks_2samp(data[col1], data[col2])\n",
    "    print(f\"{col1}-{col2}: {ks_stat:.4f}\")\n",
    "\n",
    "# Visualize using KDE plots to show initial distribution shapes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for col in data.columns:\n",
    "    data[col].plot.kde(label=col, ax=ax)\n",
    "\n",
    "plt.title('Initial distributions (all similar)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff2854",
   "metadata": {},
   "source": [
    "## 2. Maximize structural diversity while preserving mean and standard deviation similarity\n",
    "\n",
    "### 2.1. Objective function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_similar_means_stds_diverse_structures(w, x, y, z):\n",
    "    '''Maximize structural diversity while maintaining similar means and standard deviations.\n",
    "    \n",
    "    Objective function: mean_ks_statistic - penalty_weight * (mean_penalty + std_penalty)\n",
    "    \n",
    "    This encourages:\n",
    "        - Similar means across all 4 distributions (w, x, y, z)\n",
    "        - Similar standard deviations across all 4 distributions\n",
    "        - Maximum structural diversity between distributions (high pairwise KS statistics)\n",
    "    \n",
    "    The objective constrains both first and second moments while maximizing shape differences.\n",
    "    \n",
    "    Args:\n",
    "        w, x, y, z: Four variables (array-like)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (metrics_dict, objective_value) where:\n",
    "            - metrics_dict: Dict with means, stds, KS statistics, and penalties\n",
    "            - objective_value: mean_ks_statistic - penalty_weight * (mean_penalty + std_penalty)\n",
    "    '''\n",
    "    \n",
    "    # Calculate means for all 4 distributions\n",
    "    means = {\n",
    "        'w': np.mean(w),\n",
    "        'x': np.mean(x), \n",
    "        'y': np.mean(y),\n",
    "        'z': np.mean(z)\n",
    "    }\n",
    "    \n",
    "    # Calculate standard deviations for all 4 distributions\n",
    "    stds = {\n",
    "        'w': np.std(w),\n",
    "        'x': np.std(x),\n",
    "        'y': np.std(y),\n",
    "        'z': np.std(z)\n",
    "    }\n",
    "    \n",
    "    # Calculate target mean and std (average across all distributions)\n",
    "    target_mean = np.mean(list(means.values()))\n",
    "    target_std = np.mean(list(stds.values()))\n",
    "    \n",
    "    # Calculate mean penalty - how far each mean is from the target\n",
    "    mean_deviations = [abs(mean_val - target_mean) for mean_val in means.values()]\n",
    "    mean_penalty = np.mean(mean_deviations)  # Absolute deviation, no normalization\n",
    "    \n",
    "    # Calculate std penalty - how far each std is from the target\n",
    "    std_deviations = [abs(std_val - target_std) for std_val in stds.values()]\n",
    "    std_penalty = np.mean(std_deviations)  # Absolute deviation, no normalization\n",
    "    \n",
    "    # Calculate pairwise KS statistics to measure structural diversity\n",
    "    distributions = {'w': w, 'x': x, 'y': y, 'z': z}\n",
    "    ks_statistics = {}\n",
    "    ks_values = []\n",
    "    \n",
    "    for name1, name2 in combinations(distributions.keys(), 2):\n",
    "        ks_stat, _ = stats.ks_2samp(distributions[name1], distributions[name2])\n",
    "        ks_statistics[f'KS_{name1}_{name2}'] = ks_stat\n",
    "        ks_values.append(ks_stat)\n",
    "    \n",
    "    # Mean KS statistic - higher means more structural diversity\n",
    "    mean_ks_statistic = np.mean(ks_values)\n",
    "    min_ks_statistic = np.min(ks_values)\n",
    "    max_ks_statistic = np.max(ks_values)\n",
    "    \n",
    "    # Objective: maximize structural diversity while maintaining similar means and stds\n",
    "    # Scale KS statistic to similar magnitude as penalties (KS in [0,1], multiply by 10)\n",
    "    penalty_weight = 5.0  # Balance between diversity and constraint satisfaction\n",
    "    combined_penalty = mean_penalty + std_penalty\n",
    "    objective = (10.0 * mean_ks_statistic) - (penalty_weight * combined_penalty)\n",
    "    \n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        'Mean W': means['w'],\n",
    "        'Mean X': means['x'],\n",
    "        'Mean Y': means['y'],\n",
    "        'Mean Z': means['z'],\n",
    "        'Std W': stds['w'],\n",
    "        'Std X': stds['x'],\n",
    "        'Std Y': stds['y'],\n",
    "        'Std Z': stds['z'],\n",
    "        'Target Mean': target_mean,\n",
    "        'Target Std': target_std,\n",
    "        'Mean Penalty': mean_penalty,\n",
    "        'Std Penalty': std_penalty,\n",
    "        'Combined Penalty': combined_penalty,\n",
    "        'Mean KS Statistic': mean_ks_statistic,\n",
    "        'Min KS Statistic': min_ks_statistic,\n",
    "        'Max KS Statistic': max_ks_statistic,\n",
    "        **ks_statistics  # Add individual pairwise KS statistics\n",
    "    }\n",
    "    \n",
    "    return metrics, objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d87636",
   "metadata": {},
   "source": [
    "### 2.2. Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for faster convergence with structural diversity\n",
    "step_size = 1.5  # Smaller steps for more controlled changes\n",
    "perturb_fraction = 0.2  # Perturb fewer points at once\n",
    "temperature = 100.0  # Lower initial temperature for more selective acceptance\n",
    "initial_noise = 1.0  # Moderate noise for diverse starting points\n",
    "cooling_rate = 0.9995  # Faster cooling for quicker convergence\n",
    "objective_func = objective_similar_means_stds_diverse_structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed99240",
   "metadata": {},
   "source": [
    "### 2.3. Hill climbing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HillClimber instance\n",
    "climber = HillClimber(\n",
    "    data=data,\n",
    "    objective_func=objective_func,\n",
    "    max_time=run_time,\n",
    "    step_size=step_size,\n",
    "    perturb_fraction=perturb_fraction,\n",
    "    temperature=temperature,\n",
    "    cooling_rate=cooling_rate,\n",
    "    mode='maximize'\n",
    ")\n",
    "\n",
    "# Run parallel optimization\n",
    "results = climber.climb_parallel(\n",
    "    replicates=replicates,\n",
    "    initial_noise=initial_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe922e",
   "metadata": {},
   "source": [
    "### 2.4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key metrics using histograms\n",
    "climber.plot_results(\n",
    "    results,\n",
    "    plot_type='histogram', \n",
    "    metrics=[\n",
    "        'Mean Penalty',\n",
    "        'Std Penalty',\n",
    "        'Combined Penalty',\n",
    "        'Mean KS Statistic',\n",
    "        'Min KS Statistic',\n",
    "        'Max KS Statistic'\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2675f",
   "metadata": {},
   "source": [
    "### 2.5. Best result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6696ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the best result's distributions\n",
    "print(\"=\"*60)\n",
    "print(\"BEST RESULT VISUALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the replicate with highest objective value\n",
    "best_idx = np.argmax([steps_df['Objective value'].iloc[-1] \n",
    "                      for _, _, steps_df in results['results']])\n",
    "noisy_initial_best, best_data_final, best_steps = results['results'][best_idx]\n",
    "\n",
    "print(f\"Best replicate: {best_idx + 1}\")\n",
    "print(f\"Final objective: {best_steps['Objective value'].iloc[-1]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"Final statistics:\")\n",
    "for col in best_data_final.columns:\n",
    "    print(f\"  {col.upper()}: mean={np.mean(best_data_final[col]):.2f}, std={np.std(best_data_final[col]):.2f}\")\n",
    "\n",
    "# Plot individual histograms for each distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "for i, col in enumerate(best_data_final.columns):\n",
    "    ax = axes[i]\n",
    "    ax.hist(best_data_final[col], bins=30, color=colors[i], edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{col.upper()} (μ={np.mean(best_data_final[col]):.2f}, σ={np.std(best_data_final[col]):.2f})', \n",
    "                 fontsize=12)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "fig.suptitle('Best Result: 4 Distributions with Similar Means & Stds but Different Shapes', \n",
    "             fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe504b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the climber object\n",
    "with open('../data/03_similar_means_diverse_structures.pkl', 'wb') as f:\n",
    "    pickle.dump(climber, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
