{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbffe72d",
   "metadata": {},
   "source": [
    "# Example climb: Low Pearson correlation & low entropy\n",
    "\n",
    "## 1. Notebook setup\n",
    "\n",
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18280f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr, entropy\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from hill_climber import HillClimber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e3660",
   "metadata": {},
   "source": [
    "### 1.2. Run hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d285bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input data points\n",
    "n = 5000\n",
    "\n",
    "# Run duration in minutes\n",
    "run_time = 60\n",
    "\n",
    "# Number of replicate climbs\n",
    "replicates = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc8f04",
   "metadata": {},
   "source": [
    "### 1.3. Input distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e82f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input distribution\n",
    "data = pd.DataFrame({\n",
    "    'x': np.random.rand(n),\n",
    "    'y': np.random.rand(n)\n",
    "})\n",
    "\n",
    "plt.title('Input data')\n",
    "plt.scatter(data['x'], data['y'], s=5, color='black')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206508cd",
   "metadata": {},
   "source": [
    "## 2. Minimize correlation and entropy\n",
    "\n",
    "### 2.1. Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_concentration_penalty(data, edge_threshold=0.05):\n",
    "    \"\"\"Penalize having too many points near the edges [0, 1]\"\"\"\n",
    "    try:\n",
    "        if len(data) < 3:\n",
    "            return 0.0\n",
    "        \n",
    "        # Count points very close to 0 or 1\n",
    "        near_zero = np.sum(data < edge_threshold)\n",
    "        near_one = np.sum(data > (1.0 - edge_threshold))\n",
    "        edge_count = near_zero + near_one\n",
    "        \n",
    "        # Penalty increases with edge concentration\n",
    "        edge_fraction = edge_count / len(data)\n",
    "        \n",
    "        # Penalize if more than 20% of points are on edges\n",
    "        if edge_fraction > 0.2:\n",
    "            return (edge_fraction - 0.2) * 5.0  # Strong penalty\n",
    "        return 0.0\n",
    "        \n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def outlier_penalty(data):\n",
    "    try:\n",
    "        if len(data) < 3:\n",
    "            return 0.0\n",
    "\n",
    "        mean_val = np.mean(data)\n",
    "        std_val = np.std(data)\n",
    "\n",
    "        if std_val == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # Count points more than 2.5 standard deviations from mean\n",
    "        z_scores = np.abs((data - mean_val) / std_val)\n",
    "        outliers = np.sum(z_scores > 2.5)\n",
    "        return outliers / len(data)\n",
    "\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def internal_structure_reward(x, y):\n",
    "    \"\"\"Reward configurations with varied local density (patterns, clusters, etc.)\"\"\"\n",
    "    try:\n",
    "        # Divide space into grid and measure density variation\n",
    "        n_grid = 5\n",
    "        grid_counts = np.zeros((n_grid, n_grid))\n",
    "        \n",
    "        # Bin points into grid\n",
    "        x_bins = np.digitize(x, np.linspace(0, 1, n_grid + 1)) - 1\n",
    "        y_bins = np.digitize(y, np.linspace(0, 1, n_grid + 1)) - 1\n",
    "        \n",
    "        # Clip to valid range\n",
    "        x_bins = np.clip(x_bins, 0, n_grid - 1)\n",
    "        y_bins = np.clip(y_bins, 0, n_grid - 1)\n",
    "        \n",
    "        # Count points in each grid cell\n",
    "        for i in range(len(x)):\n",
    "            grid_counts[x_bins[i], y_bins[i]] += 1\n",
    "        \n",
    "        # Higher variance in grid counts = more structure\n",
    "        density_variance = np.var(grid_counts)\n",
    "        \n",
    "        # Normalize by total points\n",
    "        structure_score = density_variance / (len(x) + 1)\n",
    "        \n",
    "        return structure_score\n",
    "        \n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def objective_low_correlation_low_entropy(x, y):\n",
    "    '''Minimize both Pearson correlation and joint entropy while encouraging internal structure.\n",
    "    \n",
    "    Objective encourages diverse solutions with internal patterns rather than edge concentration.\n",
    "    '''\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # Basic validation\n",
    "    if len(x) == 0 or len(y) == 0 or len(x) != len(y):\n",
    "        return {'error': 'invalid_input'}, -1000.0\n",
    "    \n",
    "    # Calculate Pearson correlation (with fallback)\n",
    "    try:\n",
    "        pearson_corr = pearsonr(x, y)[0]\n",
    "\n",
    "        if np.isnan(pearson_corr):\n",
    "            pearson_corr = 0.0\n",
    "\n",
    "    except:\n",
    "        pearson_corr = 0.0\n",
    "    \n",
    "    # Calculate joint entropy using 2D histogram\n",
    "    try:\n",
    "        n_bins = 20\n",
    "        hist_2d, _, _ = np.histogram2d(x, y, bins=n_bins)\n",
    "        hist_flat = hist_2d.flatten()\n",
    "        \n",
    "        if hist_flat.sum() == 0:\n",
    "            joint_entropy = 0.0\n",
    "\n",
    "        else:\n",
    "            hist_prob = hist_flat / hist_flat.sum()\n",
    "            joint_entropy = entropy(hist_prob + 1e-10)\n",
    "            \n",
    "    except:\n",
    "        joint_entropy = 5.0\n",
    "    \n",
    "    # Add penalty for edge concentration (discourages pushing points to boundaries)\n",
    "    edge_penalty_x = edge_concentration_penalty(x)\n",
    "    edge_penalty_y = edge_concentration_penalty(y)\n",
    "    total_edge_penalty = edge_penalty_x + edge_penalty_y\n",
    "    \n",
    "    # Add outlier penalty using standard deviations\n",
    "    outlier_penalty_x = outlier_penalty(x)\n",
    "    outlier_penalty_y = outlier_penalty(y)\n",
    "    total_outlier_penalty = outlier_penalty_x + outlier_penalty_y\n",
    "    \n",
    "    # Encourage internal structure by rewarding moderate spread\n",
    "    # (not too compact, not filling entire space)\n",
    "    x_range = np.ptp(x)  # max - min\n",
    "    y_range = np.ptp(y)\n",
    "    \n",
    "    # Ideal range is moderate use of [0,1] space (encourages clustering/patterns)\n",
    "    ideal_min_range = 0.4  # At least 40% of space\n",
    "    ideal_max_range = 0.8  # At most 80% of space (less than before)\n",
    "    \n",
    "    range_penalty = 0.0\n",
    "\n",
    "    if x_range < ideal_min_range:\n",
    "        range_penalty += (ideal_min_range - x_range) ** 2\n",
    "\n",
    "    elif x_range > ideal_max_range:\n",
    "        range_penalty += (x_range - ideal_max_range) ** 2\n",
    "        \n",
    "    if y_range < ideal_min_range:\n",
    "        range_penalty += (ideal_min_range - y_range) ** 2\n",
    "\n",
    "    elif y_range > ideal_max_range:\n",
    "        range_penalty += (y_range - ideal_max_range) ** 2\n",
    "    \n",
    "    # Reward for having internal structure (measured by local density variation)\n",
    "    internal_structure = internal_structure_reward(x, y)\n",
    "    \n",
    "    # Balanced objective with penalties and rewards\n",
    "    correlation_penalty = 0.4 * abs(pearson_corr)  # Slightly increased weight\n",
    "    entropy_penalty = 0.4 * joint_entropy  # Slightly increased weight\n",
    "    outlier_penalty_weighted = 0.8 * total_outlier_penalty  # Reduced from 1.0\n",
    "    range_penalty_weighted = 0.5 * range_penalty  # Increased from 0.3\n",
    "    edge_penalty_weighted = 2.0 * total_edge_penalty  # Strong penalty for edges\n",
    "    structure_reward = 0.3 * internal_structure  # Reward internal structure\n",
    "    \n",
    "    objective = -(correlation_penalty + entropy_penalty + outlier_penalty_weighted + \n",
    "                  range_penalty_weighted + edge_penalty_weighted) + structure_reward\n",
    "    \n",
    "    metrics = {\n",
    "        'Pearson coefficient': float(pearson_corr),\n",
    "        'Joint Entropy': float(joint_entropy),\n",
    "        'Outlier Penalty': float(total_outlier_penalty),\n",
    "        'Range Penalty': float(range_penalty),\n",
    "        'Edge Penalty': float(total_edge_penalty),\n",
    "        'Internal Structure': float(internal_structure),\n",
    "        'Combined Score': float(correlation_penalty + entropy_penalty)\n",
    "    }\n",
    "    \n",
    "    return metrics, float(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feaa673",
   "metadata": {},
   "source": [
    "### 2.2. Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0587c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for diversity and internal structure\n",
    "step_size = 0.5  # Reduced for more controlled exploration\n",
    "perturb_fraction = 0.15  # Reduced to allow gradual evolution\n",
    "temperature = 500.0  # Higher temperature for more exploration\n",
    "initial_noise = 0.5  # Higher initial diversity between replicates\n",
    "cooling_rate = 0.9995  # Slower cooling to maintain diversity longer\n",
    "objective_func = objective_low_correlation_low_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756bef8",
   "metadata": {},
   "source": [
    "### 2.3. Hill climbing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HillClimber instance\n",
    "climber = HillClimber(\n",
    "    data=data,\n",
    "    objective_func=objective_func,\n",
    "    max_time=run_time,\n",
    "    step_size=step_size,\n",
    "    perturb_fraction=perturb_fraction,\n",
    "    temperature=temperature,\n",
    "    cooling_rate=cooling_rate,\n",
    "    mode='maximize'\n",
    ")\n",
    "\n",
    "# Run parallel optimization\n",
    "results = climber.climb_parallel(\n",
    "    replicates=replicates,\n",
    "    initial_noise=initial_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f8ffd",
   "metadata": {},
   "source": [
    "### 2.4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key metrics including new edge penalty and internal structure\n",
    "climber.plot_results(\n",
    "    results,\n",
    "    metrics=[\n",
    "        'Joint Entropy',\n",
    "        'Edge Penalty',\n",
    "        'Internal Structure',\n",
    "        'Pearson coefficient'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the climber object\n",
    "with open('../data/04_low_correlation_low_entropy.pkl', 'wb') as f:\n",
    "    pickle.dump(climber, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
