{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbffe72d",
   "metadata": {},
   "source": [
    "# Example climb: Low Pearson correlation & low entropy\n",
    "\n",
    "## 1. Notebook setup\n",
    "\n",
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18280f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr, entropy\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from hill_climber import HillClimber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e3660",
   "metadata": {},
   "source": [
    "### 1.2. Run hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d285bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input data points\n",
    "n = 5000\n",
    "\n",
    "# Run duration in minutes\n",
    "run_time = 60\n",
    "\n",
    "# Number of replicate climbs\n",
    "replicates = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc8f04",
   "metadata": {},
   "source": [
    "### 1.3. Input distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e82f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input distribution\n",
    "data = pd.DataFrame({\n",
    "    'x': np.random.rand(n),\n",
    "    'y': np.random.rand(n)\n",
    "})\n",
    "\n",
    "plt.title('Input data')\n",
    "plt.scatter(data['x'], data['y'], s=5, color='black')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206508cd",
   "metadata": {},
   "source": [
    "## 2. Minimize correlation and entropy\n",
    "\n",
    "### 2.1. Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_low_correlation_low_entropy(x, y):\n",
    "    '''Minimize both Pearson correlation and joint entropy while preventing outliers.\n",
    "    \n",
    "    Balanced objective that allows optimization progress while discouraging extreme points.\n",
    "    '''\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # Basic validation\n",
    "    if len(x) == 0 or len(y) == 0 or len(x) != len(y):\n",
    "        return {'error': 'invalid_input'}, -1000.0\n",
    "    \n",
    "    # Calculate Pearson correlation (with fallback)\n",
    "    try:\n",
    "        pearson_corr = pearsonr(x, y)[0]\n",
    "\n",
    "        if np.isnan(pearson_corr):\n",
    "            pearson_corr = 0.0\n",
    "\n",
    "    except:\n",
    "        pearson_corr = 0.0\n",
    "    \n",
    "    # Calculate joint entropy using 2D histogram\n",
    "    try:\n",
    "        n_bins = 20\n",
    "        hist_2d, _, _ = np.histogram2d(x, y, bins=n_bins)\n",
    "        hist_flat = hist_2d.flatten()\n",
    "        \n",
    "        if hist_flat.sum() == 0:\n",
    "            joint_entropy = 0.0\n",
    "\n",
    "        else:\n",
    "            hist_prob = hist_flat / hist_flat.sum()\n",
    "            joint_entropy = entropy(hist_prob + 1e-10)\n",
    "            \n",
    "    except:\n",
    "        joint_entropy = 5.0\n",
    "    \n",
    "    # Add outlier penalty using standard deviations (gentler than IQR)\n",
    "    def outlier_penalty(data):\n",
    "\n",
    "        try:\n",
    "            if len(data) < 3:\n",
    "                return 0.0\n",
    "\n",
    "            mean_val = np.mean(data)\n",
    "            std_val = np.std(data)\n",
    "\n",
    "            if std_val == 0:\n",
    "                return 0.0\n",
    "\n",
    "            # Count points more than 2 standard deviations from mean\n",
    "            z_scores = np.abs((data - mean_val) / std_val)\n",
    "            outliers = np.sum(z_scores > 2.5)\n",
    "            return outliers / len(data)\n",
    "\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    outlier_penalty_x = outlier_penalty(x)\n",
    "    outlier_penalty_y = outlier_penalty(y)\n",
    "    total_outlier_penalty = outlier_penalty_x + outlier_penalty_y\n",
    "    \n",
    "    # Encourage reasonable data spread (not too compact, not too spread)\n",
    "    x_range = np.ptp(x)  # max - min\n",
    "    y_range = np.ptp(y)\n",
    "    \n",
    "    # Ideal range is moderate use of [0,1] space\n",
    "    ideal_min_range = 0.3  # At least 30% of space\n",
    "    ideal_max_range = 0.9  # At most 90% of space\n",
    "    \n",
    "    range_penalty = 0.0\n",
    "\n",
    "    if x_range < ideal_min_range:\n",
    "        range_penalty += (ideal_min_range - x_range)\n",
    "\n",
    "    elif x_range > ideal_max_range:\n",
    "        range_penalty += (x_range - ideal_max_range)\n",
    "        \n",
    "    if y_range < ideal_min_range:\n",
    "        range_penalty += (ideal_min_range - y_range)\n",
    "\n",
    "    elif y_range > ideal_max_range:\n",
    "        range_penalty += (y_range - ideal_max_range)\n",
    "    \n",
    "    # Balanced objective with moderate penalties\n",
    "    correlation_penalty = 0.3 * abs(pearson_corr)\n",
    "    entropy_penalty = 0.3 * joint_entropy\n",
    "    outlier_penalty_weighted = 1.0 * total_outlier_penalty  # Strong outlier penalty\n",
    "    range_penalty_weighted = 0.3 * range_penalty\n",
    "    \n",
    "    objective = -(correlation_penalty + entropy_penalty + outlier_penalty_weighted + range_penalty_weighted)\n",
    "    \n",
    "    metrics = {\n",
    "        'Pearson coefficient': float(pearson_corr),\n",
    "        'Joint Entropy': float(joint_entropy),\n",
    "        'Outlier Penalty': float(total_outlier_penalty),\n",
    "        'Range Penalty': float(range_penalty),\n",
    "        'Combined Score': float(correlation_penalty + entropy_penalty)\n",
    "    }\n",
    "    \n",
    "    return metrics, float(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feaa673",
   "metadata": {},
   "source": [
    "### 2.2. Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0587c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters - more aggressive for faster progress\n",
    "step_size = 1.0\n",
    "perturb_fraction = 0.2\n",
    "temperature = 100.0\n",
    "initial_noise = 0.3\n",
    "cooling_rate = 0.999\n",
    "objective_func = objective_low_correlation_low_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756bef8",
   "metadata": {},
   "source": [
    "### 2.3. Hill climbing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HillClimber instance\n",
    "climber = HillClimber(\n",
    "    data=data,\n",
    "    objective_func=objective_func,\n",
    "    max_time=run_time,\n",
    "    step_size=step_size,\n",
    "    perturb_fraction=perturb_fraction,\n",
    "    temperature=temperature,\n",
    "    cooling_rate=cooling_rate,\n",
    "    mode='maximize'\n",
    ")\n",
    "\n",
    "# Run parallel optimization\n",
    "results = climber.climb_parallel(\n",
    "    replicates=replicates,\n",
    "    initial_noise=initial_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f8ffd",
   "metadata": {},
   "source": [
    "### 2.4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key metrics including outlier penalty\n",
    "climber.plot_results(results, metrics=['Joint Entropy', 'Outlier Penalty', 'Pearson coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the climber object\n",
    "with open('../data/04_low_correlation_low_entropy.pkl', 'wb') as f:\n",
    "    pickle.dump(climber, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
