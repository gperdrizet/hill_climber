{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8420eb24",
   "metadata": {},
   "source": [
    "# Example climb: Feature interactions with weak individual correlations\n",
    "\n",
    "## 1. Notebook setup\n",
    "\n",
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374e7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from hill_climber import HillClimber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13cac3",
   "metadata": {},
   "source": [
    "### 1.2. Run hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b51131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input data points\n",
    "n = 5000\n",
    "\n",
    "# Run duration in minutes\n",
    "run_time = 60\n",
    "\n",
    "# Number of replicate climbs\n",
    "replicates = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d96b7e",
   "metadata": {},
   "source": [
    "### 1.3. Input distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1edcbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data statistics:\n",
      "                x1           x2           x3            y\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000\n",
      "mean      4.968320     4.914871     5.013751     5.076847\n",
      "std       2.896337     2.856165     2.907698     2.878062\n",
      "min       0.000116     0.000528     0.001577     0.002525\n",
      "25%       2.438628     2.471459     2.471673     2.627293\n",
      "50%       5.000086     4.859716     4.961971     5.124496\n",
      "75%       7.481009     7.333716     7.606190     7.511056\n",
      "max       9.997177     9.995052     9.998051     9.999248\n",
      "\n",
      "Initial correlations with label:\n",
      "x1-y: 0.0287\n",
      "x2-y: -0.0004\n",
      "x3-y: 0.0071\n",
      "\n",
      "Initial Multiple Linear Regression R²: 0.0009\n"
     ]
    }
   ],
   "source": [
    "# Create input distributions: 3 features (x1, x2, x3) and 1 label (y)\n",
    "# Start with random uniform distributions\n",
    "np.random.seed(42)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'x1': np.random.uniform(0, 10, n),\n",
    "    'x2': np.random.uniform(0, 10, n),\n",
    "    'x3': np.random.uniform(0, 10, n),\n",
    "    'y': np.random.uniform(0, 10, n)\n",
    "})\n",
    "\n",
    "print(\"Initial data statistics:\")\n",
    "print(data.describe())\n",
    "print(\"\\nInitial correlations with label:\")\n",
    "\n",
    "for col in ['x1', 'x2', 'x3']:\n",
    "    corr, _ = pearsonr(data[col], data['y'])\n",
    "    print(f\"{col}-y: {corr:.4f}\")\n",
    "\n",
    "# Check initial linear regression R²\n",
    "X = data[['x1', 'x2', 'x3']].values\n",
    "y = data['y'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"\\nInitial Multiple Linear Regression R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92456229",
   "metadata": {},
   "source": [
    "## 2. Optimize for weak individual correlations but strong collective prediction\n",
    "\n",
    "### 2.1. Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c70311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_feature_interactions(x1, x2, x3, y):\n",
    "    '''Maximize multiple linear regression R² while minimizing individual feature-label correlations.\n",
    "    \n",
    "    This creates datasets where features interact to predict the label, but individual features\n",
    "    alone are poor predictors. This demonstrates the importance of feature interactions.\n",
    "    \n",
    "    Args:\n",
    "        x1, x2, x3: Feature variables (array-like)\n",
    "        y: Label variable (array-like)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (metrics_dict, objective_value)\n",
    "    '''\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    x1 = np.asarray(x1)\n",
    "    x2 = np.asarray(x2)\n",
    "    x3 = np.asarray(x3)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # Validation\n",
    "    if len(x1) < 10 or len(x1) != len(x2) or len(x1) != len(x3) or len(x1) != len(y):\n",
    "        return {'error': 'invalid_input'}, -1000.0\n",
    "    \n",
    "    try:\n",
    "        # Calculate individual Pearson correlations with label\n",
    "        corr_x1_y, _ = pearsonr(x1, y)\n",
    "        corr_x2_y, _ = pearsonr(x2, y)\n",
    "        corr_x3_y, _ = pearsonr(x3, y)\n",
    "        \n",
    "        # Handle NaN correlations\n",
    "        if np.isnan(corr_x1_y):\n",
    "            corr_x1_y = 0.0\n",
    "        if np.isnan(corr_x2_y):\n",
    "            corr_x2_y = 0.0\n",
    "        if np.isnan(corr_x3_y):\n",
    "            corr_x3_y = 0.0\n",
    "        \n",
    "        # Average absolute correlation (want this LOW)\n",
    "        avg_individual_corr = np.mean([abs(corr_x1_y), abs(corr_x2_y), abs(corr_x3_y)])\n",
    "        max_individual_corr = np.max([abs(corr_x1_y), abs(corr_x2_y), abs(corr_x3_y)])\n",
    "        \n",
    "    except Exception as e:\n",
    "        avg_individual_corr = 0.0\n",
    "        max_individual_corr = 0.0\n",
    "        corr_x1_y = 0.0\n",
    "        corr_x2_y = 0.0\n",
    "        corr_x3_y = 0.0\n",
    "    \n",
    "    try:\n",
    "        # Calculate multiple linear regression R² (want this HIGH)\n",
    "        X = np.column_stack([x1, x2, x3])\n",
    "        \n",
    "        # Check for valid variance\n",
    "        if np.std(y) < 1e-6:\n",
    "            mlr_r2 = 0.0\n",
    "\n",
    "        else:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            y_pred = model.predict(X)\n",
    "            mlr_r2 = r2_score(y, y_pred)\n",
    "            \n",
    "            # Clip R² to valid range\n",
    "            mlr_r2 = np.clip(mlr_r2, -1.0, 1.0)\n",
    "            \n",
    "    except Exception as e:\n",
    "        mlr_r2 = 0.0\n",
    "    \n",
    "    try:\n",
    "        # Calculate pairwise feature correlations (want moderate values for diversity)\n",
    "        corr_x1_x2, _ = pearsonr(x1, x2)\n",
    "        corr_x1_x3, _ = pearsonr(x1, x3)\n",
    "        corr_x2_x3, _ = pearsonr(x2, x3)\n",
    "        \n",
    "        # Handle NaN\n",
    "        if np.isnan(corr_x1_x2):\n",
    "            corr_x1_x2 = 0.0\n",
    "\n",
    "        if np.isnan(corr_x1_x3):\n",
    "            corr_x1_x3 = 0.0\n",
    "\n",
    "        if np.isnan(corr_x2_x3):\n",
    "            corr_x2_x3 = 0.0\n",
    "        \n",
    "        avg_feature_corr = np.mean([abs(corr_x1_x2), abs(corr_x1_x3), abs(corr_x2_x3)])\n",
    "        \n",
    "    except Exception as e:\n",
    "        corr_x1_x2 = 0.0\n",
    "        corr_x1_x3 = 0.0\n",
    "        corr_x2_x3 = 0.0\n",
    "        avg_feature_corr = 0.0\n",
    "    \n",
    "    # Penalty for high individual correlations with label\n",
    "    individual_corr_penalty = 10.0 * avg_individual_corr\n",
    "    \n",
    "    # Penalty for extremely high max individual correlation\n",
    "    max_corr_penalty = 5.0 * max(0, max_individual_corr - 0.3)  # Penalize if > 0.3\n",
    "    \n",
    "    # Reward for high MLR R² (scale to similar magnitude)\n",
    "    mlr_reward = 20.0 * max(0, mlr_r2)  # Only reward positive R²\n",
    "    \n",
    "    # Penalty for extreme feature intercorrelations (want some but not perfect)\n",
    "    # Ideal is moderate correlation (around 0.3-0.6)\n",
    "    feature_corr_penalty = 0.0\n",
    "\n",
    "    if avg_feature_corr > 0.8:  # Too correlated\n",
    "        feature_corr_penalty = 3.0 * (avg_feature_corr - 0.8)\n",
    "\n",
    "    elif avg_feature_corr < 0.1:  # Too independent\n",
    "        feature_corr_penalty = 2.0 * (0.1 - avg_feature_corr)\n",
    "    \n",
    "    # Calculate objective: maximize MLR R², minimize individual correlations\n",
    "    objective = mlr_reward - individual_corr_penalty - max_corr_penalty - feature_corr_penalty\n",
    "    \n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        'MLR R²': float(mlr_r2),\n",
    "        'Avg Individual Corr': float(avg_individual_corr),\n",
    "        'Max Individual Corr': float(max_individual_corr),\n",
    "        'Corr x1-y': float(corr_x1_y),\n",
    "        'Corr x2-y': float(corr_x2_y),\n",
    "        'Corr x3-y': float(corr_x3_y),\n",
    "        'Avg Feature Corr': float(avg_feature_corr),\n",
    "        'Corr x1-x2': float(corr_x1_x2),\n",
    "        'Corr x1-x3': float(corr_x1_x3),\n",
    "        'Corr x2-x3': float(corr_x2_x3),\n",
    "        'Individual Corr Penalty': float(individual_corr_penalty),\n",
    "        'MLR Reward': float(mlr_reward)\n",
    "    }\n",
    "    \n",
    "    return metrics, float(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ea881",
   "metadata": {},
   "source": [
    "### 2.2. Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005335e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for feature interaction optimization\n",
    "step_size = 1.0\n",
    "perturb_fraction = 0.15\n",
    "temperature = 100.0\n",
    "initial_noise = 0.5\n",
    "cooling_rate = 0.9995\n",
    "objective_func = objective_feature_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44226af8",
   "metadata": {},
   "source": [
    "### 2.3. Hill climbing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f996e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HillClimber instance\n",
    "climber = HillClimber(\n",
    "    data=data,\n",
    "    objective_func=objective_func,\n",
    "    max_time=run_time,\n",
    "    step_size=step_size,\n",
    "    perturb_fraction=perturb_fraction,\n",
    "    temperature=temperature,\n",
    "    cooling_rate=cooling_rate,\n",
    "    mode='maximize'\n",
    ")\n",
    "\n",
    "# Run parallel optimization\n",
    "results = climber.climb_parallel(\n",
    "    replicates=replicates,\n",
    "    initial_noise=initial_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a3497",
   "metadata": {},
   "source": [
    "### 2.4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf100415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key metrics\n",
    "climber.plot_results(\n",
    "    results,\n",
    "    plot_type='histogram',\n",
    "    metrics=[\n",
    "        'MLR R²',\n",
    "        'Avg Individual Corr',\n",
    "        'Max Individual Corr',\n",
    "        'Avg Feature Corr'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f11bf2",
   "metadata": {},
   "source": [
    "### 2.5. Best result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best result\n",
    "print(\"=\"*60)\n",
    "print(\"BEST RESULT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the replicate with highest objective value\n",
    "best_idx = np.argmax([steps_df['Objective value'].iloc[-1] \n",
    "                      for _, _, steps_df in results['results']])\n",
    "noisy_initial_best, best_data_final, best_steps = results['results'][best_idx]\n",
    "\n",
    "print(f\"Best replicate: {best_idx + 1}\")\n",
    "print(f\"Final objective: {best_steps['Objective value'].iloc[-1]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Extract best features and label\n",
    "X_best = best_data_final[['x1', 'x2', 'x3']].values\n",
    "y_best = best_data_final['y'].values\n",
    "\n",
    "# Individual correlations\n",
    "print(\"Individual feature-label correlations (want LOW):\")\n",
    "for col in ['x1', 'x2', 'x3']:\n",
    "    corr, p_val = pearsonr(best_data_final[col], best_data_final['y'])\n",
    "    print(f\"  {col}-y: {corr:7.4f} (p={p_val:.4f})\")\n",
    "\n",
    "avg_corr = np.mean([abs(pearsonr(best_data_final[col], best_data_final['y'])[0]) \n",
    "                    for col in ['x1', 'x2', 'x3']])\n",
    "print(f\"  Average: {avg_corr:7.4f}\")\n",
    "print()\n",
    "\n",
    "# Feature intercorrelations\n",
    "print(\"Feature-feature correlations:\")\n",
    "corr_x1_x2, _ = pearsonr(best_data_final['x1'], best_data_final['x2'])\n",
    "corr_x1_x3, _ = pearsonr(best_data_final['x1'], best_data_final['x3'])\n",
    "corr_x2_x3, _ = pearsonr(best_data_final['x2'], best_data_final['x3'])\n",
    "print(f\"  x1-x2: {corr_x1_x2:7.4f}\")\n",
    "print(f\"  x1-x3: {corr_x1_x3:7.4f}\")\n",
    "print(f\"  x2-x3: {corr_x2_x3:7.4f}\")\n",
    "print()\n",
    "\n",
    "# Multiple Linear Regression\n",
    "print(\"Multiple Linear Regression (want HIGH R²):\")\n",
    "model_best = LinearRegression()\n",
    "model_best.fit(X_best, y_best)\n",
    "y_pred_best = model_best.predict(X_best)\n",
    "r2_best = r2_score(y_best, y_pred_best)\n",
    "\n",
    "print(f\"  R² Score: {r2_best:.4f}\")\n",
    "print(f\"  Coefficients: {model_best.coef_}\")\n",
    "print(f\"  Intercept: {model_best.intercept_:.4f}\")\n",
    "print()\n",
    "\n",
    "# Calculate what R² would be for each feature alone\n",
    "print(\"Individual feature regression R² (for comparison):\")\n",
    "for i, col in enumerate(['x1', 'x2', 'x3']):\n",
    "    X_single = best_data_final[[col]].values\n",
    "    model_single = LinearRegression()\n",
    "    model_single.fit(X_single, y_best)\n",
    "    y_pred_single = model_single.predict(X_single)\n",
    "    r2_single = r2_score(y_best, y_pred_single)\n",
    "    print(f\"  {col} alone: {r2_single:.4f}\")\n",
    "\n",
    "print()\n",
    "print(f\"Improvement factor: {r2_best / max(0.001, avg_corr**2):.2f}x\")\n",
    "print(\"(MLR R² vs. avg squared individual correlation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27dc8fd",
   "metadata": {},
   "source": [
    "### 2.6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654700a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature-label relationships and predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Individual feature plots\n",
    "for i, col in enumerate(['x1', 'x2', 'x3']):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.scatter(best_data_final[col], y_best, s=10, alpha=0.5)\n",
    "    ax.set_xlabel(col, fontsize=12)\n",
    "    ax.set_ylabel('y (label)', fontsize=12)\n",
    "    \n",
    "    # Add correlation to title\n",
    "    corr, _ = pearsonr(best_data_final[col], y_best)\n",
    "    ax.set_title(f'{col} vs y (r={corr:.3f})', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Predicted vs actual\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(y_best, y_pred_best, s=10, alpha=0.5)\n",
    "ax.plot([y_best.min(), y_best.max()], [y_best.min(), y_best.max()], \n",
    "        'r--', lw=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual y', fontsize=12)\n",
    "ax.set_ylabel('Predicted y (MLR)', fontsize=12)\n",
    "ax.set_title(f'MLR Predictions (R²={r2_best:.3f})', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Feature Interactions: Weak Individual Correlations, Strong Collective Prediction', \n",
    "             fontsize=14, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the climber object\n",
    "with open('../data/06_feature_interactions.pkl', 'wb') as f:\n",
    "    pickle.dump(climber, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
